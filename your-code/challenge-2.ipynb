{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Challenge 2\n",
    "\n",
    "In this challenge we will continue working with the `Pokemon` dataset. We will attempt solving a slightly more complex problem in which we will practice the iterative data analysis process you leaned in [this video](https://www.youtube.com/watch?v=xOomNicqbkk).\n",
    "\n",
    "The problem statement is as follows:\n",
    "\n",
    "**You are at a Pokemon black market planning to buy a Pokemon for battle. All Pokemon are sold at the same price and you can only afford to buy one. You cannot choose which specific Pokemon to buy. However, you can specify the type of the Pokemon - one type that exists in either `Type 1` or `Type 2`. Which type should you choose in order to maximize your chance of receiving a good Pokemon?**\n",
    "\n",
    "To remind you about the 3 steps of iterative data analysis, they are:\n",
    "\n",
    "1. Setting Expectations\n",
    "1. Collecting Information\n",
    "1. Reacting to Data / Revising Expectations\n",
    "\n",
    "Following the iterative process, we'll guide you in completing the challenge."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Problem Solving Iteration 1\n",
    "\n",
    "In this iteration we'll analyze the problem and identify the breakthrough. The original question statement is kind of vague because we don't know what a *good pokemon* really means as represented in the data. We'll start by understanding the dataset and see if we can find some insights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Importing the dataset from Ironhack's database\n",
    "pokemon = pd.read_csv('Pokemon.csv') \n",
    "pokemon"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the data it seems whether a pokemon is good depends on its abilities as represented in the fields of `HP`, `Attack`, `Defense`, `Sp. Atk`, `Sp. Def`, `Speed`, and `Total`. We are not sure about `Generation` and `Legendary` because they are not necessarily the decisive factors of the pokemon abilities.\n",
    "\n",
    "But `HP`, `Attack`, `Defense`, `Sp. Atk`, `Sp. Def`, `Speed`, and `Total` are a lot of fields! If we look at them all at once it's very complicated. This isn't Mission Impossible but it's ideal that we tackle this kind of problem after we learn Machine Learning (which you will do in Module 3). For now, is there a way to consolidate the fields we need to look into?\n",
    "\n",
    "Fortunately there seems to be a way. It appears the `Total` field is computed based on the other 6 fields. But we need to prove our theory. If we can approve there is a formula to compute `Total` based on the other 6 abilities, we only need to look into `Total`.\n",
    "\n",
    "We have the following expectation now:\n",
    "\n",
    "#### The `Total` field is computed based on `HP`, `Attack`, `Defense`, `Sp. Atk`, `Sp. Def`, and `Speed`.\n",
    "\n",
    "We need to collect the following information:\n",
    "\n",
    "* **What is the formula to compute `Total`?**\n",
    "* **Does the formula work for all pokemon?**\n",
    "\n",
    "In the cell below, make a hypothesis on how `Total` is computed and test your hypothesis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pokemon = pokemon.drop(columns=\"Hypothesis\")\n",
    "pokemon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n",
    "pokemon['Hypothesis']= pokemon.iloc[:, -7:-1].sum(axis=1)\n",
    "pokemon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem Solving Iteration 2\n",
    "\n",
    "Now that we have consolidated the abilities fields, we can update the problem statement. The new problem statement is:\n",
    "\n",
    "### Which pokemon type is most likely to have the highest `Total` value?\n",
    "\n",
    "In the updated problem statement, we assume there is a certain relationship between the `Total` and the pokemon type. But we have two *type* fields (`Type 1` and `Type 2`) that have string values. In data analysis, string fields have to be transformed to numerical format in order to be analyzed. \n",
    "\n",
    "In addition, keep in mind that `Type 1` always has a value but `Type 2` is sometimes empty (having the `NaN` value). Also, the pokemon type we choose may be either in `Type 1` or `Type 2`.\n",
    "\n",
    "Now our expectation is:\n",
    "\n",
    "#### `Type 1` and `Type 2` string variables need to be converted to numerical variables in order to identify the relationship between `Total` and the pokemon type.\n",
    "\n",
    "The information we need to collect is:\n",
    "\n",
    "#### How to convert two string variables to numerical?\n",
    "\n",
    "Let's address the first question first. You can use a method called **One Hot Encoding** which is frequently used in machine learning to encode categorical string variables to numerical. The idea is to gather all the possible string values in a categorical field and create a numerical field for each unique string value. Each of those numerical fields uses `1` and `0` to indicate whether the data record has the corresponding categorical value. A detailed explanation of One Hot Encoding can be found in [this article](https://hackernoon.com/what-is-one-hot-encoding-why-and-when-do-you-have-to-use-it-e3c6186d008f). You will formally learn it in Module 3.\n",
    "\n",
    "For instance, if a pokemon has `Type 1` as `Poison` and `Type 2` as `Fire`, then its `Poison` and `Fire` fields are `1` whereas all other fields are `0`. If a pokemon has `Type 1` as `Water` and `Type 2` as `NaN`, then its `Water` field is `1` whereas all other fields are `0`.\n",
    "\n",
    "#### In the next cell, use One Hot Encoding to encode `Type 1` and `Type 2`. Use the pokemon type values as the names of the numerical fields you create.\n",
    "\n",
    "The new numerical variables you create should look like below:\n",
    "\n",
    "![One Hot Encoding](../images/one-hot-encoding.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n",
    "def name_combo(row):\n",
    "    if pd.isnull(row['Type 2']):\n",
    "        return row['Type 1']\n",
    "    else:\n",
    "        return row['Type 1'] + '-' + row['Type 2']\n",
    "pokemon['NameCombo']=pokemon[['Type 1', 'Type 2']].apply(name_combo, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pokemon['Type 1'].unique()\n",
    "\n",
    "encoding_table = pokemon[['Type 1', 'Type 2']]\n",
    "\n",
    "encoding_table\n",
    "\n",
    "\n",
    "def name_combo2(row):\n",
    "    if pd.isnull(row['Type 2']):\n",
    "        return row['Type 1']\n",
    "    else:\n",
    "        return row['Type 1'] + '-' + row['Type 2']\n",
    "encoding_table['NameCombo']=encoding_table[['Type 1', 'Type 2']].apply(name_combo2, axis = 1)\n",
    "encoding_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoding_table\n",
    "\n",
    "# Get one hot encoding of columns B\n",
    "one_hot = pd.get_dummies(encoding_table['Type 1'])\n",
    "# Drop column B as it is now encoded\n",
    "encoding_table = encoding_table.drop('Type 1',axis = 1)\n",
    "# Join the encoded df\n",
    "encoding_table = encoding_table.join(one_hot)\n",
    "encoding_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from collections import defaultdict\n",
    "\n",
    "d = defaultdict(LabelBinarizer)\n",
    "\n",
    "cols2bnrz = ['Type 1','Type 2']\n",
    "\n",
    "In [8]: df[cols2bnrz].apply(lambda x: d[x.name].fit(x))\n",
    "\n",
    "    \n",
    "In [10]: new = pd.DataFrame({\n",
    "    ...:     'Reference': [6, 7],\n",
    "    ...:     'Brand': ['Volvo', 'Audi'],\n",
    "    ...:     'Town': ['Stockholm', 'Munich']\n",
    "    ...: })\n",
    "\n",
    "In [11]: new\n",
    "\n",
    "In [12]: pd.DataFrame(d['Brand'].transform(new['Brand']), columns=d['Brand'].classes_)\n",
    "\n",
    "In [13]: pd.DataFrame(d['Town'].transform(new['Town']), columns=d['Town'].classes_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OrdinalEncoder, OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all the unique values if we don't have them\n",
    "unique_values = pd.unique(tmp_ohe1.values.ravel()) \n",
    "unique_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#encoding_table = encoding_table.replace(np.nan, '', regex=True)\n",
    "tmp_ohe = pokemon[['Type 1', 'Type 2']]\n",
    "tmp_ohe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Get all the unique values if we don't have them\n",
    "unique_values = pd.unique(tmp_ohe1.values.ravel()) \n",
    "\n",
    "ohe = OneHotEncoder(categories=[unique_values]*len(tmp_ohe1), sparse=False)\n",
    "encoded = pd.DataFrame(ohe.fit_transform(tmp_ohe1), columns=ohe.get_feature_names(tmp_ohe1.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoding_table = pokemon[['Type 1', 'Type 2']]\n",
    "\n",
    "encoding_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_ohe\n",
    "import numpy as np\n",
    "tmp_ohe1 = tmp_ohe.replace(np.nan, 'a', regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_ohe1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_t1 = pokemon[['Name','Type 1']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Length of 'prefix' (1) did not match the length of the columns being encoded (2).",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-85-ef165728c7d5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpreprocessing\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_dummies\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mp_t1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mprefix\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Type 1'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\reshape\\reshape.py\u001b[0m in \u001b[0;36mget_dummies\u001b[1;34m(data, prefix, prefix_sep, dummy_na, columns, sparse, drop_first, dtype)\u001b[0m\n\u001b[0;32m    823\u001b[0m                     \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen_msg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    824\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 825\u001b[1;33m         \u001b[0mcheck_len\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprefix\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'prefix'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    826\u001b[0m         \u001b[0mcheck_len\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprefix_sep\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'prefix_sep'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    827\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\reshape\\reshape.py\u001b[0m in \u001b[0;36mcheck_len\u001b[1;34m(item, name)\u001b[0m\n\u001b[0;32m    821\u001b[0m                     len_msg = len_msg.format(name=name, len_item=len(item),\n\u001b[0;32m    822\u001b[0m                                              len_enc=data_to_encode.shape[1])\n\u001b[1;32m--> 823\u001b[1;33m                     \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen_msg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    824\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    825\u001b[0m         \u001b[0mcheck_len\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprefix\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'prefix'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Length of 'prefix' (1) did not match the length of the columns being encoded (2)."
     ]
    }
   ],
   "source": [
    "p_t1\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "import pandas\n",
    "from sklearn import preprocessing \n",
    "\n",
    "pd.get_dummies(p_t1,prefix=['Type 1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing one hot encoder from sklearn \n",
    "from sklearn.preprocessing import OneHotEncoder \n",
    "  \n",
    "#creating one hot encoder object by default \n",
    "# entire data passed is one hot encoded \n",
    "onehotencoder = OneHotEncoder() \n",
    "  \n",
    "data = onehotencoder.fit_transform(p_t1).toarray() \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoding_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.get_dummies(encoding_table,dummy_na=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pokemon['Type 1'].unique()\n",
    "\n",
    "\n",
    "'Grass'\n",
    "'Poison'\n",
    "'Fire' \n",
    "'Flying'\n",
    "'Dragon'\n",
    "'Water'\n",
    "'Bug' \n",
    "'Normal'\n",
    "'Electric'\n",
    "'Ground' \n",
    "'Fairy' \n",
    "'Fighting' \n",
    "'Psychic' \n",
    "'Rock' \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    'Ghost', 'Ice',\n",
    "       '', 'Dark', 'Steel', ''], dtype=object)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem Solving Iteration 3\n",
    "\n",
    "Now we have encoded the pokemon types, we will identify the relationship between `Total` and the encoded fields. Our expectation is:\n",
    "\n",
    "#### There are relationships between `Total` and the encoded pokemon type variables and we need to identify the correlations.\n",
    "\n",
    "The information we need to collect is:\n",
    "\n",
    "#### How to identify the relationship between `Total` and the encoded pokemon type fields?\n",
    "\n",
    "There are multiple ways to answer this question. The easiest way is to use correlation. In the cell below, calculate the correlation of `Total` to each of the encoded fields. Rank the correlations and identify the #1 pokemon type that is most likely to have the highest `Total`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bonus Question\n",
    "\n",
    "Say now you can choose both `Type 1` and `Type 2` of the pokemon. In order to receive the best pokemon, which types will you choose?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
